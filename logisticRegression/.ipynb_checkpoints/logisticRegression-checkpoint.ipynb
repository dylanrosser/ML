{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 97.33%\n"
     ]
    }
   ],
   "source": [
    "# Simple logistic regression example using iris dataset\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "X, y = load_iris(return_X_y=True)\n",
    "clf = LogisticRegression(random_state=0, solver='lbfgs', multi_class='auto', max_iter=1000).fit(X, y)\n",
    "preds = clf.predict(X)\n",
    "\n",
    "# calculate training accuracy\n",
    "correct_pred = (preds == y).astype(float)\n",
    "acc = correct_pred.sum() / len(correct_pred)\n",
    "print('accuracy: {0:0.2f}%'.format(acc*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Logistic Regression on Iris Dataset\n",
    "**Using a Neural Net in Pytorch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multinomial Logistic Regression on Iris Dataset using a Neural Net from Pytorch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ta\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "X, y = load_iris(return_X_y=True)\n",
    "x_data = Variable(torch.Tensor(X))\n",
    "y_data = Variable(torch.Tensor(y))\n",
    "y_data = y_data.long()\n",
    "\n",
    "class LogisticRegression(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = torch.nn.Linear(4, 3)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        y_pred = self.linear(x)\n",
    "        return y_pred\n",
    "    \n",
    "model = LogisticRegression()\n",
    "# no need for explicit softmax layer, its included in CrossEntropyLoss\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 98.67%\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(20000):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    # Forward pass\n",
    "    y_pred = model(x_data)\n",
    "    # Compute Loss\n",
    "    loss = criterion(y_pred, y_data)\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "# One more pass on training data\n",
    "y_pred = model(x_data)\n",
    "y_pred_softmax = F.log_softmax(y_pred, dim=1)\n",
    "_, y_pred_label = torch.max(y_pred_softmax, dim = 1)\n",
    "\n",
    "# calculate training accuracy\n",
    "correct_pred = (y_pred_label == y_data).float()\n",
    "acc = correct_pred.sum() / len(correct_pred)\n",
    "print('accuracy: {0:0.2f}%'.format(acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Logistic Regression on MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coming Soon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
